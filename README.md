# BYOL with Vision Transformer (ViT)

ì´ ë ˆí¬ì§€í† ë¦¬ëŠ” **Bootstrap Your Own Latent (BYOL)** í”„ë ˆì„ì›Œí¬ì—ì„œ ê¸°ì¡´ ResNet ë°±ë³¸ì„ **Vision Transformer (ViT)** ë¡œ ëŒ€ì²´í•˜ì—¬ êµ¬í˜„í•œ ìê¸°ì§€ë„í•™ìŠµ ëª¨ë¸ì…ë‹ˆë‹¤.  
ë°ì´í„°ì…‹ìœ¼ë¡œëŠ” **Tiny-ImageNet**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

## ğŸ” ì£¼ìš” íŠ¹ì§•
- BYOL êµ¬ì¡°ì—ì„œ ë°±ë³¸ì„ Vision Transformerë¡œ ë³€ê²½
- HuggingFace `ViTModel` ì‚¬ìš©
- BatchNorm ì œê±° ë° MLP êµ¬ì¡° ìˆ˜ì •
- Tiny-ImageNetì„ ê¸°ë°˜ìœ¼ë¡œ ìê¸°ì§€ë„ ì‚¬ì „í•™ìŠµ
- ì„ í˜• í”„ë¡œë¹™ì„ í†µí•œ ì„±ëŠ¥ í‰ê°€ ì§€ì›

## ğŸ“ ë°ì´í„°ì…‹ ì¤€ë¹„
- Tiny-ImageNet ë‹¤ìš´ë¡œë“œ í›„ `tiny-imagenet-200` ë””ë ‰í† ë¦¬ êµ¬ì„± í•„ìš”
  
  ```bash
  wget http://cs231n.stanford.edu/tiny-imagenet-200.zip
  ```
- **`val/` ë””ë ‰í† ë¦¬ëŠ” í´ë˜ìŠ¤ë³„ í•˜ìœ„ í´ë”ë¡œ ë¶„ë¥˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤**
> `val_annotations.txt` íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ validation ì´ë¯¸ì§€ë¥¼ í´ë˜ìŠ¤ë³„ í´ë”ë¡œ ì •ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

## ğŸ›  ì„¤ì¹˜
```bash
git clone https://github.com/ha-erim/byol_vit.git
cd byol_vit
pip install -r requirements.txt
```

## ğŸš€ ì‚¬ìš©ë²•

### 1. BYOL ì‚¬ì „í•™ìŠµ
```bash
torchrun --nproc_per_node=2 main.py \
    --data_root /path/to/tiny-imagenet-200 \
    --batch_size 128 \
    --epochs 30 \
    --lr 0.05 \
    --mode train
```

### 2. ì„ í˜• í”„ë¡œë¹™ (Linear Evaluation)
```bash
python main.py \
    --mode test \
    --data_root /path/to/tiny-imagenet-200 \
    --weight /path/to/checkpoints/byol_epoch19.pth
```
